{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0d56242-1595-490f-8c76-f90a0e4aeb99",
   "metadata": {},
   "source": [
    "# Linear Regression and Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a5bfb5-7a7b-493c-aa3d-bc08b003c52e",
   "metadata": {},
   "source": [
    "In this notebook, we'll look at using linear regression to study changes in temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f60dfe4-21fc-4e81-8297-9e9f6e006257",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43c3a2a2-fbff-43b3-917d-61cb9febac2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "%config InlineBackend.figure_format ='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b423dcd9-e160-4579-a05c-0762b512f71b",
   "metadata": {},
   "source": [
    "## Getting our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261788d7-7bf0-4fb4-a862-2cb4d00d458c",
   "metadata": {},
   "source": [
    "We'll be getting data from [North America Land Data Assimilation System (NLDAS)](https://wonder.cdc.gov/NASA-NLDAS.html), which provides the daily average temperature from 1979-2011 for the United States."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7188eb-5e92-4630-a692-7fcc639f9cdf",
   "metadata": {},
   "source": [
    "For the next step, you will need to choose some settings in the data request form. These are:\n",
    "\n",
    "- GroupBy: Month Day, Year\n",
    "- Your State\n",
    "- Export Results (check box)\n",
    "- Show Zero Values (check box)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081d3fc2-81a3-4c81-a9fa-f9d00c97a9ad",
   "metadata": {},
   "source": [
    ">1) Download the data for your home state (or state of your choosing) and upload it to M2 in your work directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f5b0ba-c195-4ed0-973f-73c4def133f0",
   "metadata": {},
   "source": [
    "# Loading our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08784dbd-1975-4576-a278-f51e573f49ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'North America Land Data Assimilation System (NLDAS) Daily Air Temperatures and Heat Index (1979-2011).txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1f242b1378e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'North America Land Data Assimilation System (NLDAS) Daily Air Temperatures and Heat Index (1979-2011).txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskipfooter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'python'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/ds_1300/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ds_1300/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ds_1300/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ds_1300/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ds_1300/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, **kwds)\u001b[0m\n\u001b[1;32m   2291\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2292\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2293\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2294\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2295\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"readline\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ds_1300/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ds_1300/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'North America Land Data Assimilation System (NLDAS) Daily Air Temperatures and Heat Index (1979-2011).txt'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('North America Land Data Assimilation System (NLDAS) Daily Air Temperatures and Heat Index (1979-2011).txt',delimiter='\\t',skipfooter=14,engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97ab2d9-3f4e-4baf-9b52-8e8c2c39c778",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b91f5e-adb8-48dc-bcc8-1fecbe635a39",
   "metadata": {},
   "source": [
    "### Clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6c4527-c277-45f9-a4af-4be1db61fb09",
   "metadata": {},
   "source": [
    ">2) Drop any rows that have the value \"Total\" in the Notes column, then drop the Notes column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636bf430-6df7-4677-97d4-566e4ed8b1a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "796b53ae-30e1-4614-b737-6fa49115d913",
   "metadata": {},
   "source": [
    ">3) Make a column called Date that is in the pandas datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9407f6a8-83b1-4395-9243-70e3841340a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e6c8647-4785-41ef-9577-d23d2366f8a6",
   "metadata": {},
   "source": [
    ">4) Make columns for 'Year', 'Month', and 'Day' by splitting the column 'Month Day, Year'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9a2aef-be38-425a-8c2a-77520adf53ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aab6cb-d7aa-4ab0-9a8a-cff800cf3a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DateInt'] = df['Date'].astype(int)/10e10 # This will be used later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba94a96-cc87-481c-b069-dbd72cbf2645",
   "metadata": {},
   "source": [
    "## Generating a scatter plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18ec1a8-76b7-4a44-8ce8-d93ead497b99",
   "metadata": {},
   "source": [
    "> 4) Use df.plot.scatter to plot 'Date' vs 'Avg Daily Max Air Temperature (F)'. You might want to add figsize=(50,5) as an argument to make it more clear what is happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1666605d-ba00-4d54-aa50-9bfaf8e27666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "023a04ec-d87b-45b7-bbf9-f422550ed4c7",
   "metadata": {},
   "source": [
    ">5) Describe your plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3427c3e-3325-4ab6-bf99-f2e6a0528ce5",
   "metadata": {},
   "source": [
    "### Adding colors for our graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05976c1e-3c63-4238-bec3-956a3bc15743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to edit this unless you want to try different colors or a pattern other than colors by month\n",
    "\n",
    "cmap = matplotlib.cm.get_cmap(\"nipy_spectral\", len(df['Month'].unique())) # Builds a discrete color mapping using a built in matplotlib color map\n",
    "\n",
    "c = []\n",
    "for i in range(cmap.N): # Converts our discrete map into Hex Values\n",
    "    rgba = cmap(i)\n",
    "    c.append(matplotlib.colors.rgb2hex(rgba))\n",
    "\n",
    "df['color']=[c[int(i-1)] for i in df['Month'].astype(int)] # Adds a column to our dataframe with the color we want for each row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab3d130-2f70-416e-8b4f-c6f74f8277bb",
   "metadata": {},
   "source": [
    ">6) Make the same plot as 4) but add color by adding the argument c=df\\['color'\\] to our plotting command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebed007-7c08-4da5-9704-edd8d4b0e67b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0593dbbb-28a3-43c9-9f11-a459bb301851",
   "metadata": {},
   "source": [
    "## Pick a subset of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cacb114-efb2-4b61-ba54-ccace1b5908a",
   "metadata": {},
   "source": [
    ">7) Select a 6 month period from the data. # Hint use logic and pd.datetime(YYYY, MM, DD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17dc6fb-a374-4bca-8943-f6fa5f7c9966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "983a1477-08e4-4120-95e5-91f8c99c2dd6",
   "metadata": {},
   "source": [
    ">8) Plot the subset using the the same code you used in 6). You can change the figsize if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3972d2-745d-479e-8e4a-64194e2b672c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcbf9a45-818e-4f4d-b2a7-5cc77f7c464b",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0805c3f-e919-47da-bece-ffcd8f30ffac",
   "metadata": {},
   "source": [
    "We are going to use a very [simple linear regression model](https://en.wikipedia.org/wiki/Simple_linear_regression). You may implement a more complex model if you wish.\n",
    "\n",
    "The method described here is called the least squares method and is defined as:\n",
    "\n",
    "$m = \\frac{\\sum_{i=1}^{n}(x_i-\\bar{x})(y_i-\\bar{y}))}{\\sum_{i=1}^{n}(x_i-\\bar{x})^2}$\n",
    "\n",
    "$b = \\bar{y} - m\\bar{x}$\n",
    "\n",
    "Where $\\bar{x}$ and $\\bar{y}$ are the average value of $x$ and $y$ respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebefc03f-5a62-4eed-a170-cc2f131baa67",
   "metadata": {},
   "source": [
    "First we need to define our X and Y values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db0c1aa-e520-465c-875b-c865765b7c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=subset['DateInt'].values\n",
    "Y=subset['Avg Daily Max Air Temperature (F)'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0febfa4d-0323-4a3e-bfff-bcd2983ae3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_reg(x,y):\n",
    "    # Calculate the average x and y\n",
    "    x_avg = np.mean(x)\n",
    "    y_avg = np.mean(y)\n",
    "\n",
    "    num = 0\n",
    "    den = 0\n",
    "    for i in range(len(x)): # This represents our sums\n",
    "        num = num + (x[i] - x_avg)*(y[i] - y_avg) # Our numerator\n",
    "        den = den + (x[i] - x_avg)**2 # Our denominator\n",
    "    # Calculate slope\n",
    "    m = num / den\n",
    "    # Calculate intercept\n",
    "    b = y_avg - m*x_avg\n",
    "\n",
    "    print (m, b)\n",
    "    \n",
    "    # Calculate our predicted y values\n",
    "    y_pred = m*x + b\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392e1f48-b7b3-4e2c-97b8-6f9159df1cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = lin_reg(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d297bc3f-4458-47c3-bb42-78747b53f7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.plot.scatter(x='Date', y='Avg Daily Max Air Temperature (F)',c=subset['color'])\n",
    "plt.plot([min(subset['Date'].values), max(subset['Date'].values)], [min(Y_pred), max(Y_pred)], color='red') # best fit line\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106eb911-7137-4db2-82af-579b3c9c0629",
   "metadata": {},
   "source": [
    ">9) What are the slope and intercept of your best fit line?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1d7254-0daa-4beb-8c1b-8008a409479b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a78d82a3-68a9-46d2-9cf2-296550519fb5",
   "metadata": {},
   "source": [
    ">10) What are the minimum and maximum Y values of your best fit line? Is your slope positive or negative?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79f6640-e3f9-4272-9054-ace9b8dadc1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff4d4890-adf6-4ab9-ae3d-49a6ae8b83e0",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e065808a-7fac-426e-a0e3-3c7272feb2e1",
   "metadata": {},
   "source": [
    ">11) Generate a best fit line for the full data set and plot the line over top of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb7887f-6c1e-4669-8531-ea57630a4c43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4149f4d-6f66-40ce-9085-20af6fad8532",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20fdb979-89eb-471f-87c8-f70c15c95e52",
   "metadata": {},
   "source": [
    ">12) Is the slope positive or negative? What do you think that means?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d8978c-58d4-40d1-92f1-d2e4ce66a8cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
